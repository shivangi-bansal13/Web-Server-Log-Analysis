{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81debeba",
   "metadata": {},
   "source": [
    "## Part 1: Data Loading and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b2c05313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\bansa\\appdata\\roaming\\python\\python313\\site-packages (2.3.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\bansa\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\bansa\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bansa\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\bansa\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bansa\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install pandas \n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b2f35398-acf7-4574-90a8-e0f07b2aa04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving data file path \n",
    "file_path= r'C:\\Users\\bansa\\Downloads\\calgary_access_log'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b31475d2-b93a-4838-aab3-7e78e25be5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apache-style log pattern through regex\n",
    "\n",
    "#data ex.- local - - [24/Oct/1994:13:41:41 -0600] \"GET index.html HTTP/1.0\" 200 150\n",
    "\n",
    "log_pattern = re.compile(\n",
    "    r'(?P<host>\\S+) \\S+ \\S+ \\[(?P<timestamp>[^\\]]+)\\] \"(?P<method>\\S+)? (?P<resource>\\S+)? (?P<protocol>[^\"]+)?\" (?P<status>\\d{3}) (?P<bytes>\\S+)'\n",
    ")           #syntax (?P<name>...)\n",
    "\n",
    "\n",
    "# Timestamp parser\n",
    "#converting dateTime from time into date time object of pandas\n",
    "def parse_timestamp(time):\n",
    "    try:\n",
    "        return datetime.strptime(time.split()[0], \"%d/%b/%Y:%H:%M:%S\")\n",
    "    except:\n",
    "        return pd.NaT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c01f9345-9324-4308-9858-c8bd1d3ee310",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing through data and storing it in data frame\n",
    "data = []\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "    for line in file:\n",
    "        match = log_pattern.match(line)\n",
    "        if match:\n",
    "            data_entry = match.groupdict()\n",
    "            data_entry['timestamp'] = parse_timestamp(data_entry['timestamp'])\n",
    "            data_entry['bytes'] = int(data_entry['bytes']) if data_entry['bytes'].isdigit() else 0\n",
    "            data_entry['status'] = int(data_entry['status'])\n",
    "\n",
    "            # Extract file extension from the requested resource\n",
    "            extension_match = re.search(r'\\.([a-zA-Z0-9]+)(?:[\\?#]|$)', data_entry.get(\"resource\") or \"\")\n",
    "            data_entry['file_ext'] = extension_match.group(1).lower() if extension_match else None\n",
    "\n",
    "            #if these 3 colns are  present in any row then only we will append that data_entry \n",
    "            if all([data_entry['timestamp'], data_entry['method'], data_entry['resource']]):\n",
    "            \n",
    "                data.append(data_entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d580e95-6ec8-44c4-935a-cc6c4256dca4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>method</th>\n",
       "      <th>resource</th>\n",
       "      <th>protocol</th>\n",
       "      <th>status</th>\n",
       "      <th>bytes</th>\n",
       "      <th>file_ext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>local</td>\n",
       "      <td>1994-10-24 13:41:41</td>\n",
       "      <td>GET</td>\n",
       "      <td>index.html</td>\n",
       "      <td>HTTP/1.0</td>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "      <td>html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>local</td>\n",
       "      <td>1994-10-24 13:41:41</td>\n",
       "      <td>GET</td>\n",
       "      <td>1.gif</td>\n",
       "      <td>HTTP/1.0</td>\n",
       "      <td>200</td>\n",
       "      <td>1210</td>\n",
       "      <td>gif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>local</td>\n",
       "      <td>1994-10-24 13:43:13</td>\n",
       "      <td>GET</td>\n",
       "      <td>index.html</td>\n",
       "      <td>HTTP/1.0</td>\n",
       "      <td>200</td>\n",
       "      <td>3185</td>\n",
       "      <td>html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>local</td>\n",
       "      <td>1994-10-24 13:43:14</td>\n",
       "      <td>GET</td>\n",
       "      <td>2.gif</td>\n",
       "      <td>HTTP/1.0</td>\n",
       "      <td>200</td>\n",
       "      <td>2555</td>\n",
       "      <td>gif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>local</td>\n",
       "      <td>1994-10-24 13:43:15</td>\n",
       "      <td>GET</td>\n",
       "      <td>3.gif</td>\n",
       "      <td>HTTP/1.0</td>\n",
       "      <td>200</td>\n",
       "      <td>36403</td>\n",
       "      <td>gif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    host           timestamp method    resource  protocol  status  bytes  \\\n",
       "0  local 1994-10-24 13:41:41    GET  index.html  HTTP/1.0     200    150   \n",
       "1  local 1994-10-24 13:41:41    GET       1.gif  HTTP/1.0     200   1210   \n",
       "2  local 1994-10-24 13:43:13    GET  index.html  HTTP/1.0     200   3185   \n",
       "3  local 1994-10-24 13:43:14    GET       2.gif  HTTP/1.0     200   2555   \n",
       "4  local 1994-10-24 13:43:15    GET       3.gif  HTTP/1.0     200  36403   \n",
       "\n",
       "  file_ext  \n",
       "0     html  \n",
       "1      gif  \n",
       "2     html  \n",
       "3      gif  \n",
       "4      gif  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting  it into DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Drop malformed entries if any\n",
    "\n",
    "required_cols = ['timestamp', 'method', 'resource']                       #list of column names that are necessary for analysis\n",
    "\n",
    "df.dropna(subset=required_cols, inplace=True)         #drop row if there is \"NA\" in these required_cols\n",
    "\n",
    "\n",
    "\n",
    "# Type casting\n",
    "#making sure that data types are correct\n",
    "df = df.astype({\n",
    "    \"host\": str,\n",
    "    \"method\": str,\n",
    "    \"resource\": str,\n",
    "    \"protocol\": str,\n",
    "    \"status\": int,\n",
    "    \"bytes\": int,\n",
    "    \"file_ext\": \"object\"\n",
    "})\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Preview cleaned data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80da5c6e",
   "metadata": {},
   "source": [
    "## Part 2: Analysis Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afff13fe",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Q1: Count of total log records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f6264dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1:\n",
      "724036\n"
     ]
    }
   ],
   "source": [
    "def total_log_records() -> int:\n",
    "    \"\"\"\n",
    "    Q1: Count of total log records.\n",
    "\n",
    "    Objective:\n",
    "        Determine the total number of HTTP log entries in the dataset.\n",
    "        Each line in the log file represents one HTTP request.\n",
    "\n",
    "    Returns:\n",
    "        int: Total number of log entries.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement logic to count log records\n",
    "    return len(df)\n",
    "\n",
    "    return 0  # Placeholder return\n",
    "\n",
    "\n",
    "answer1 = total_log_records()\n",
    "print(\"Answer 1:\")\n",
    "print(answer1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c5141e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Q2: Count of unique hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fcbccae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 2:\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "def unique_host_count() -> int:\n",
    "    \"\"\"\n",
    "    Q2: Count of unique hosts.\n",
    "\n",
    "    Objective:\n",
    "        Determine how many distinct hosts accessed the server.\n",
    "\n",
    "    Returns:\n",
    "        int: Number of unique hosts.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement logic to count unique hosts\n",
    "    df_new=df[\"host\"].nunique()\n",
    "    return df_new\n",
    "\n",
    "    return 0  # Placeholder return\n",
    "\n",
    "\n",
    "answer2 = unique_host_count()\n",
    "print(\"Answer 2:\")\n",
    "print(answer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c224d5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Q3: Date-wise unique filename counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ac11c680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 3:\n",
      "{'01-Apr-1995': 436, '01-Aug-1995': 672, '01-Dec-1994': 271, '01-Feb-1995': 622, '01-Jan-1995': 88, '01-Jul-1995': 387, '01-Jun-1995': 590, '01-Mar-1995': 582, '01-May-1995': 467, '01-Nov-1994': 412, '01-Oct-1995': 554, '01-Sep-1995': 328, '02-Apr-1995': 466, '02-Aug-1995': 857, '02-Dec-1994': 324, '02-Feb-1995': 524, '02-Jan-1995': 141, '02-Jul-1995': 399, '02-Jun-1995': 515, '02-Mar-1995': 600, '02-May-1995': 701, '02-Nov-1994': 427, '02-Oct-1995': 871, '02-Sep-1995': 351, '03-Apr-1995': 795, '03-Aug-1995': 584, '03-Dec-1994': 189, '03-Feb-1995': 569, '03-Jan-1995': 310, '03-Jul-1995': 438, '03-Jun-1995': 398, '03-Mar-1995': 505, '03-May-1995': 589, '03-Nov-1994': 460, '03-Oct-1995': 847, '03-Sep-1995': 213, '04-Apr-1995': 821, '04-Aug-1995': 717, '04-Dec-1994': 212, '04-Feb-1995': 561, '04-Jan-1995': 324, '04-Jul-1995': 612, '04-Jun-1995': 353, '04-Mar-1995': 403, '04-May-1995': 684, '04-Nov-1994': 404, '04-Oct-1995': 891, '04-Sep-1995': 342, '05-Apr-1995': 891, '05-Aug-1995': 509, '05-Dec-1994': 351, '05-Feb-1995': 484, '05-Jan-1995': 285, '05-Jul-1995': 607, '05-Jun-1995': 494, '05-Mar-1995': 471, '05-May-1995': 609, '05-Nov-1994': 194, '05-Oct-1995': 846, '05-Sep-1995': 413, '06-Apr-1995': 678, '06-Aug-1995': 448, '06-Dec-1994': 297, '06-Feb-1995': 649, '06-Jan-1995': 206, '06-Jul-1995': 524, '06-Jun-1995': 664, '06-Mar-1995': 634, '06-May-1995': 517, '06-Nov-1994': 219, '06-Oct-1995': 869, '06-Sep-1995': 549, '07-Apr-1995': 776, '07-Aug-1995': 608, '07-Dec-1994': 383, '07-Feb-1995': 696, '07-Jan-1995': 153, '07-Jul-1995': 428, '07-Jun-1995': 488, '07-Mar-1995': 765, '07-May-1995': 725, '07-Nov-1994': 364, '07-Oct-1995': 468, '07-Sep-1995': 592, '08-Apr-1995': 542, '08-Aug-1995': 656, '08-Dec-1994': 346, '08-Feb-1995': 628, '08-Jan-1995': 207, '08-Jul-1995': 277, '08-Jun-1995': 644, '08-Mar-1995': 608, '08-May-1995': 656, '08-Nov-1994': 266, '08-Oct-1995': 515, '08-Sep-1995': 756, '09-Apr-1995': 626, '09-Aug-1995': 699, '09-Dec-1994': 373, '09-Feb-1995': 711, '09-Jan-1995': 364, '09-Jul-1995': 233, '09-Jun-1995': 468, '09-Mar-1995': 687, '09-May-1995': 775, '09-Nov-1994': 338, '09-Oct-1995': 745, '09-Sep-1995': 408, '10-Apr-1995': 752, '10-Aug-1995': 637, '10-Dec-1994': 150, '10-Feb-1995': 729, '10-Jan-1995': 371, '10-Jul-1995': 504, '10-Jun-1995': 328, '10-Mar-1995': 704, '10-May-1995': 794, '10-Nov-1994': 356, '10-Oct-1995': 843, '10-Sep-1995': 455, '11-Apr-1995': 816, '11-Aug-1995': 455, '11-Dec-1994': 202, '11-Feb-1995': 359, '11-Jan-1995': 362, '11-Jul-1995': 571, '11-Jun-1995': 299, '11-Mar-1995': 468, '11-May-1995': 599, '11-Nov-1994': 297, '11-Oct-1995': 719, '11-Sep-1995': 720, '12-Apr-1995': 887, '12-Aug-1995': 342, '12-Dec-1994': 402, '12-Feb-1995': 500, '12-Jan-1995': 463, '12-Jul-1995': 469, '12-Jun-1995': 521, '12-Mar-1995': 479, '12-May-1995': 469, '12-Nov-1994': 174, '12-Sep-1995': 720, '13-Apr-1995': 614, '13-Aug-1995': 463, '13-Dec-1994': 380, '13-Feb-1995': 672, '13-Jan-1995': 427, '13-Jul-1995': 501, '13-Jun-1995': 467, '13-Mar-1995': 856, '13-May-1995': 289, '13-Nov-1994': 186, '13-Sep-1995': 774, '14-Apr-1995': 353, '14-Aug-1995': 592, '14-Dec-1994': 303, '14-Feb-1995': 707, '14-Jan-1995': 188, '14-Jul-1995': 553, '14-Jun-1995': 589, '14-Mar-1995': 779, '14-May-1995': 326, '14-Nov-1994': 331, '14-Sep-1995': 722, '15-Apr-1995': 418, '15-Aug-1995': 481, '15-Dec-1994': 281, '15-Feb-1995': 796, '15-Jan-1995': 217, '15-Jul-1995': 386, '15-Jun-1995': 479, '15-Mar-1995': 909, '15-May-1995': 584, '15-Nov-1994': 325, '15-Sep-1995': 713, '16-Apr-1995': 434, '16-Aug-1995': 604, '16-Dec-1994': 383, '16-Feb-1995': 664, '16-Jan-1995': 453, '16-Jul-1995': 299, '16-Jun-1995': 531, '16-Mar-1995': 603, '16-May-1995': 432, '16-Nov-1994': 392, '16-Sep-1995': 566, '17-Apr-1995': 446, '17-Aug-1995': 539, '17-Dec-1994': 297, '17-Feb-1995': 569, '17-Jan-1995': 381, '17-Jul-1995': 570, '17-Jun-1995': 385, '17-Mar-1995': 513, '17-May-1995': 508, '17-Nov-1994': 440, '17-Sep-1995': 468, '18-Apr-1995': 452, '18-Aug-1995': 494, '18-Dec-1994': 323, '18-Feb-1995': 549, '18-Jan-1995': 394, '18-Jul-1995': 559, '18-Jun-1995': 360, '18-Mar-1995': 418, '18-May-1995': 528, '18-Nov-1994': 404, '18-Sep-1995': 657, '19-Apr-1995': 704, '19-Aug-1995': 379, '19-Dec-1994': 365, '19-Feb-1995': 381, '19-Jan-1995': 479, '19-Jul-1995': 473, '19-Jun-1995': 614, '19-Mar-1995': 362, '19-May-1995': 499, '19-Nov-1994': 195, '19-Sep-1995': 737, '20-Apr-1995': 587, '20-Aug-1995': 397, '20-Dec-1994': 316, '20-Feb-1995': 495, '20-Jan-1995': 503, '20-Jul-1995': 569, '20-Jun-1995': 531, '20-Mar-1995': 683, '20-May-1995': 254, '20-Nov-1994': 263, '20-Sep-1995': 832, '21-Apr-1995': 713, '21-Aug-1995': 634, '21-Dec-1994': 280, '21-Feb-1995': 461, '21-Jan-1995': 259, '21-Jul-1995': 649, '21-Jun-1995': 625, '21-Mar-1995': 739, '21-May-1995': 288, '21-Nov-1994': 335, '21-Sep-1995': 801, '22-Apr-1995': 435, '22-Aug-1995': 538, '22-Dec-1994': 267, '22-Feb-1995': 708, '22-Jan-1995': 277, '22-Jul-1995': 445, '22-Jun-1995': 632, '22-Mar-1995': 620, '22-May-1995': 477, '22-Nov-1994': 351, '22-Sep-1995': 617, '23-Apr-1995': 332, '23-Aug-1995': 662, '23-Dec-1994': 157, '23-Feb-1995': 601, '23-Jan-1995': 440, '23-Jul-1995': 501, '23-Jun-1995': 561, '23-Mar-1995': 750, '23-May-1995': 565, '23-Nov-1994': 322, '23-Sep-1995': 505, '24-Apr-1995': 529, '24-Aug-1995': 579, '24-Dec-1994': 66, '24-Feb-1995': 512, '24-Jan-1995': 423, '24-Jul-1995': 567, '24-Jun-1995': 398, '24-Mar-1995': 518, '24-May-1995': 490, '24-Nov-1994': 366, '24-Oct-1994': 228, '24-Sep-1995': 595, '25-Apr-1995': 557, '25-Aug-1995': 598, '25-Dec-1994': 71, '25-Feb-1995': 470, '25-Jan-1995': 415, '25-Jul-1995': 591, '25-Jun-1995': 572, '25-Mar-1995': 615, '25-May-1995': 489, '25-Nov-1994': 324, '25-Oct-1994': 319, '25-Sep-1995': 724, '26-Apr-1995': 647, '26-Aug-1995': 398, '26-Dec-1994': 101, '26-Feb-1995': 394, '26-Jan-1995': 391, '26-Jul-1995': 598, '26-Jun-1995': 638, '26-Mar-1995': 536, '26-May-1995': 426, '26-Nov-1994': 221, '26-Oct-1994': 377, '26-Sep-1995': 871, '27-Apr-1995': 616, '27-Aug-1995': 437, '27-Dec-1994': 201, '27-Feb-1995': 530, '27-Jan-1995': 446, '27-Jul-1995': 616, '27-Jun-1995': 518, '27-Mar-1995': 837, '27-May-1995': 246, '27-Nov-1994': 187, '27-Oct-1994': 385, '27-Sep-1995': 829, '28-Apr-1995': 637, '28-Aug-1995': 552, '28-Dec-1994': 129, '28-Feb-1995': 476, '28-Jan-1995': 405, '28-Jul-1995': 566, '28-Jun-1995': 583, '28-Mar-1995': 850, '28-May-1995': 205, '28-Nov-1994': 341, '28-Oct-1994': 399, '28-Sep-1995': 870, '29-Apr-1995': 449, '29-Aug-1995': 513, '29-Dec-1994': 128, '29-Jan-1995': 368, '29-Jul-1995': 322, '29-Jun-1995': 469, '29-Mar-1995': 897, '29-May-1995': 466, '29-Nov-1994': 448, '29-Oct-1994': 254, '29-Sep-1995': 841, '30-Apr-1995': 277, '30-Aug-1995': 595, '30-Dec-1994': 132, '30-Jan-1995': 582, '30-Jul-1995': 486, '30-Jun-1995': 461, '30-Mar-1995': 862, '30-May-1995': 555, '30-Nov-1994': 354, '30-Oct-1994': 236, '30-Sep-1995': 652, '31-Aug-1995': 513, '31-Dec-1994': 94, '31-Jan-1995': 494, '31-Jul-1995': 624, '31-Mar-1995': 816, '31-May-1995': 571, '31-Oct-1994': 362}\n"
     ]
    }
   ],
   "source": [
    "def datewise_unique_filename_counts() -> dict[str, int]:\n",
    "    \"\"\"\n",
    "    Q3: Date-wise unique filename counts.\n",
    "\n",
    "    Objective:\n",
    "        For each date, count the number of unique filenames that accessed the server.\n",
    "        The date should be in 'dd-MMM-yyyy' format (e.g., '01-Jul-1995').\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping each date to its count of unique filenames.\n",
    "              Example: {'01-Jul-1995': 123, '02-Jul-1995': 150}\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement logic for date-wise unique filename counts\n",
    "    df['date']=df['timestamp'].dt.strftime('%d-%b-%Y')            #to get day-month-year format from dateTime\n",
    "    count=df.groupby('date')['resource'].nunique().to_dict()      #for each date counting no of resources and then coverting result into dict\n",
    "    return count\n",
    "    return {}  # Placeholder return\n",
    "\n",
    "\n",
    "answer3 = datewise_unique_filename_counts()\n",
    "print(\"Answer 3:\")\n",
    "print(answer3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2da36a",
   "metadata": {},
   "source": [
    "### Q4: Number of 404 response codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d0671865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 4:\n",
      "23531\n"
     ]
    }
   ],
   "source": [
    "def count_404_errors() -> int:\n",
    "    \"\"\"\n",
    "    Q4: Number of 404 response codes.\n",
    "\n",
    "    Objective:\n",
    "        Count how many times the HTTP 404 Not Found status appears in the logs.\n",
    "\n",
    "    Returns:\n",
    "        int: Number of 404 errors.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement logic to count 404 errors\n",
    "    count_404 = (df['status'] == 404).sum()       #filtering rows with status=404 and then keeping their count\n",
    "    return count_404\n",
    "\n",
    "    return 0  # Placeholder return\n",
    "\n",
    "\n",
    "answer4 = count_404_errors()\n",
    "print(\"Answer 4:\")\n",
    "print(answer4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73928d2",
   "metadata": {},
   "source": [
    "### Q5: Top 15 filenames with 404 responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "358f0523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 5:\n",
      "[('index.html', 4737), ('4115.html', 902), ('1611.html', 649), ('5698.xbm', 585), ('710.txt', 408), ('2002.html', 259), ('2177.gif', 193), ('10695.ps', 161), ('6555.html', 153), ('487.gif', 152), ('151.html', 149), ('40.html', 148), ('488.gif', 148), ('3414.gif', 148), ('9678.gif', 142)]\n"
     ]
    }
   ],
   "source": [
    "def top_15_filenames_with_404() -> list[tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Q5: Top 15 filenames with 404 responses.\n",
    "\n",
    "    Objective:\n",
    "        Identify which requested URLs most frequently resulted in a 404 error.\n",
    "        Return the top 15 filenames sorted by frequency.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples (filename, count), sorted by count in descending order.\n",
    "              Example: [('index.html', 200), ...]\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement logic to find top 15 filenames with 404\n",
    "    \n",
    "    # Filtering rows with 404 status\n",
    "    row_404 = df[df['status'] == 404]\n",
    "\n",
    "    # from these filtered rows, Count frequency of each resource (filename) that caused a 404\n",
    "    filename_counts = row_404['resource'].value_counts()   \n",
    "\n",
    "    # Sort by frequency \n",
    "    filename_counts_sorted = filename_counts.sort_values(ascending=False).head(15)\n",
    "\n",
    "    # Converting to list of tuples\n",
    "    top_404_list = list(filename_counts_sorted.items())\n",
    "\n",
    "    return top_404_list\n",
    "    return []  # Placeholder return\n",
    "\n",
    "\n",
    "answer5 = top_15_filenames_with_404()\n",
    "print(\"Answer 5:\")\n",
    "print(answer5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6328c88a",
   "metadata": {},
   "source": [
    "### Q6: Top 15 file extension with 404 responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d0aca8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 6:\n",
      "[('html', 12199), ('gif', 7340), ('xbm', 824), ('ps', 754), ('jpg', 538), ('txt', 508), ('htm', 109), ('cgi', 77), ('com', 45), ('z', 41), ('dvi', 40), ('ca', 36), ('hmtl', 30), ('util', 29), ('bmp', 28)]\n"
     ]
    }
   ],
   "source": [
    "def top_15_ext_with_404() -> list[tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Q6: Top 15 file extensions with 404 responses.\n",
    "\n",
    "    Objective:\n",
    "        Find which file extensions generated the most 404 errors.\n",
    "        Return the top 15 sorted by number of 404s.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples (extension, count), sorted by count in descending order.\n",
    "              Example: [('html', 45), ...]\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement logic to find top 15 extensions with 404\n",
    "    #filtering rows with status=404\n",
    "    df_404 = df[df['status'] == 404]\n",
    "    \n",
    "    #dropping rows with missing file extension\n",
    "    df_404_ext = df_404.dropna(subset=['file_ext'])\n",
    "\n",
    "    #Sorting by frequency \n",
    "    top_404_extensions = df_404_ext['file_ext'].value_counts().head(15)\n",
    "    return list(top_404_extensions.items())\n",
    "    return []  # Placeholder return\n",
    "\n",
    "\n",
    "answer6 = top_15_ext_with_404()\n",
    "print(\"Answer 6:\")\n",
    "print(answer6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff52c8ba",
   "metadata": {},
   "source": [
    "### Q7: Total bandwidth transferred per day for the month of July 1995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "45f52d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 7:\n",
      "{'01-Jul-1995': 11333976, '02-Jul-1995': 8656012, '03-Jul-1995': 13596612, '04-Jul-1995': 26573988, '05-Jul-1995': 19541225, '06-Jul-1995': 19755015, '07-Jul-1995': 9427822, '08-Jul-1995': 5403491, '09-Jul-1995': 4660556, '10-Jul-1995': 14916848, '11-Jul-1995': 22503471, '12-Jul-1995': 17367065, '13-Jul-1995': 15988328, '14-Jul-1995': 19186430, '15-Jul-1995': 15773233, '16-Jul-1995': 9005564, '17-Jul-1995': 19601338, '18-Jul-1995': 17098855, '19-Jul-1995': 17851725, '20-Jul-1995': 20751717, '21-Jul-1995': 25455607, '22-Jul-1995': 8066660, '23-Jul-1995': 9593870, '24-Jul-1995': 22308265, '25-Jul-1995': 24550821, '26-Jul-1995': 24638042, '27-Jul-1995': 25969995, '28-Jul-1995': 36458881, '29-Jul-1995': 11696365, '30-Jul-1995': 23189598, '31-Jul-1995': 30729809}\n"
     ]
    }
   ],
   "source": [
    "def total_bandwidth_per_day() -> dict[str, int]:\n",
    "    \"\"\"\n",
    "    Q7: Total bandwidth transferred per day for the month of July 1995.\n",
    "\n",
    "    Objective:\n",
    "        Sum the number of bytes transferred per day.\n",
    "        Skip entries where the byte field is missing or '-'.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping each date to total bytes transferred.\n",
    "              Example: {'01-Jul-1995': 123456789, ...}\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement logic to compute total bandwidth per day\n",
    "    \n",
    "    #Filter entries from July 1995\n",
    "    df_july95 = df[(df['timestamp'].dt.month == 7) & (df['timestamp'].dt.year == 1995)]\n",
    "\n",
    "    #To Ensure bytes is a numeric field (already done earlier, but just in case)\n",
    "    df_july95 = df_july95[df_july95['bytes'].notnull()]\n",
    "\n",
    "    #Create a 'date' column in desired format: '01-Jul-1995'\n",
    "    df_july95['date_str'] = df_july95['timestamp'].dt.strftime('%d-%b-%Y')\n",
    "\n",
    "    #Group by date and sum the bytes\n",
    "    bandwidth_per_day = df_july95.groupby('date_str')['bytes'].sum().to_dict()\n",
    "    return bandwidth_per_day\n",
    "    return {}  # Placeholder return\n",
    "\n",
    "\n",
    "answer7 = total_bandwidth_per_day()\n",
    "print(\"Answer 7:\")\n",
    "print(answer7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc00908",
   "metadata": {},
   "source": [
    "### Q8: Hourly request distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a77f3e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 8:\n",
      "{0: 18701, 1: 14372, 2: 12681, 3: 10895, 4: 9964, 5: 10787, 6: 13047, 7: 16659, 8: 26554, 9: 33966, 10: 43348, 11: 47570, 12: 46776, 13: 51405, 14: 54483, 15: 50269, 16: 51137, 17: 45047, 18: 33144, 19: 30546, 20: 29675, 21: 27392, 22: 23812, 23: 21806}\n"
     ]
    }
   ],
   "source": [
    "def hourly_request_distribution() -> dict[int, int]:\n",
    "    \"\"\"\n",
    "    Q8: Hourly request distribution.\n",
    "\n",
    "    Objective:\n",
    "        Count the number of requests made during each hour (00 to 23).\n",
    "        Useful for understanding traffic peaks.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping hour (int) to request count.\n",
    "              Example: {0: 120, 1: 90, ..., 23: 80}\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement logic for hourly distribution\n",
    "    df['hour'] = df['timestamp'].dt.hour            #extracting hour from dateTime\n",
    "\n",
    "    #Count number of requests per hour and coverting into dict\n",
    "    hourly_requests = df.groupby('hour').size().to_dict()         #.size() would give no of log entries in particular hour\n",
    "    return hourly_requests\n",
    "    return {}  # Placeholder return\n",
    "\n",
    "\n",
    "answer8 = hourly_request_distribution()\n",
    "print(\"Answer 8:\")\n",
    "print(answer8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363b7083",
   "metadata": {},
   "source": [
    "### Q9: Top 10 most requested filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "91168ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 9:\n",
      "[('index.html', 140074), ('3.gif', 24006), ('2.gif', 23606), ('4.gif', 8018), ('244.gif', 5149), ('5.html', 5010), ('4097.gif', 4874), ('8870.jpg', 4493), ('6733.gif', 4278), ('8472.gif', 3843)]\n"
     ]
    }
   ],
   "source": [
    "def top_10_most_requested_filenames() -> list[tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Q9: Top 10 most requested filenames.\n",
    "\n",
    "    Objective:\n",
    "        Identify the most commonly requested URLs (irrespective of status code).\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples (filename, count), sorted by count in descending order.\n",
    "                Example: [('index.html', 500), ...]\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement logic to find top 10 most requested filenames\n",
    "    \n",
    "    #Count frequency of each requested resource\n",
    "    top_10_files = df['resource'].value_counts().head(10)\n",
    "    top_10_files=top_10_files.sort_values(ascending=False)\n",
    "    #Convert to list of tuples\n",
    "    top_10_filenames = list(top_10_files.items())\n",
    "    return top_10_filenames\n",
    "    return []  # Placeholder return\n",
    "\n",
    "\n",
    "answer9 = top_10_most_requested_filenames()\n",
    "print(\"Answer 9:\")\n",
    "print(answer9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedb4778",
   "metadata": {},
   "source": [
    "### Q10: HTTP response code distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bd4453ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 10:\n",
      "{200: 567551, 304: 97792, 302: 30275, 404: 23531, 403: 4743, 401: 46, 501: 43, 500: 42, 400: 13}\n"
     ]
    }
   ],
   "source": [
    "def response_code_distribution() -> dict[int, int]:\n",
    "    \"\"\"\n",
    "    Q10: HTTP response code distribution.\n",
    "\n",
    "    Objective:\n",
    "        Count how often each HTTP status code appears in the logs.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping HTTP status codes (as int) to their frequency.\n",
    "              Example: {200: 150000, 404: 3000}\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement logic for response code counts\n",
    "\n",
    "    #taking count of each status unique value and then coverting in dict format\n",
    "    status_code_count = df['status'].value_counts().to_dict()\n",
    "    return status_code_count\n",
    "    return {}  # Placeholder return\n",
    "\n",
    "\n",
    "answer10 = response_code_distribution()\n",
    "print(\"Answer 10:\")\n",
    "print(answer10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abec966b-001f-4836-b951-29b5c62fc4e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
